{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tf2.0': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9db1de8bbe4618aac8c0dc2f33b2605f1fcbaac7d29e95e578fa6f5b02c8cb82"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers \n",
    "import time\n",
    "import dataset\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator= keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(64, 64,3)),\n",
    "        layers.Conv2D(32, (3, 3), strides=1, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.AveragePooling2D(strides=2),\n",
    "        layers.Conv2D(64, (3, 3), strides=1, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.AveragePooling2D(strides=2),\n",
    "        layers.Conv2D(64, (3, 3), strides=1, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.AveragePooling2D(strides=2),\n",
    "        layers.Conv2D(128, (3, 3), strides=1, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.AveragePooling2D(strides=2),\n",
    "        layers.Conv2D(128, 2, strides=1, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.AveragePooling2D(strides=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
    "        layers.Dense(2 * 2* 128),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dense(4 * 4 * 256),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((4, 4, 256)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128,2,1,padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128,2,1,padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128,2,1,padding=\"same\"),\n",
    "        # layers.LeakyReLU(alpha=0.2),\n",
    "        # layers.Conv2D(128,2,1,padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        # layers.LeakyReLU(alpha=0.2),\n",
    "        # layers.Conv2D(128,2,1,padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128,2,1,padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(3, 8, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator=keras.models.load_model(\"./face_dis\")\n",
    "generator=keras.models.load_model(\"./face_gen/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate one optimizer for the discriminator and another for the generator.\n",
    "d_optimizer = keras.optimizers.RMSprop(learning_rate=0.0008)\n",
    "g_optimizer = keras.optimizers.RMSprop(learning_rate=0.00008)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "# loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(real_images):\n",
    "    # Sample random points in the latent space\n",
    "    for i in range(3):\n",
    "        \n",
    "        random_vector=tf.random.normal(shape=[real_images.shape[0],latent_dim])\n",
    "        with tf.GradientTape() as tape1:\n",
    "            with tf.GradientTape() as tape2: \n",
    "                generate_image_1=generator(random_vector)\n",
    "                alph=tf.random.normal(shape=[real_images.shape[0],1,1,1])\n",
    "                generate_image_2=alph*real_images+(1-alph)*generate_image_1\n",
    "                out_real=discriminator(real_images)\n",
    "                out_gen_1=discriminator(generate_image_1)\n",
    "                out_gen_2=discriminator(generate_image_2)\n",
    "            grade_1=tape2.gradient(out_gen_2,generate_image_2)\n",
    "            grade_l2=gradien_panalty_loss(grade_1)\n",
    "            loss_dis=dis_loss(out_real,out_gen_1,grade_l2,20)\n",
    "        grade_2=tape1.gradient(loss_dis,discriminator.trainable_variables)\n",
    "        d_optimizer.apply_gradients(zip(grade_2,discriminator.trainable_variables))\n",
    "    for i in range(1):\n",
    "        random_vector=tf.random.normal(shape=[real_images.shape[0],latent_dim])\n",
    "        with tf.GradientTape() as tape:\n",
    "            generate_image= generator(random_vector)\n",
    "            out=discriminator(generate_image)\n",
    "            loss_gen=gen_loss(out)\n",
    "        grade=tape.gradient(loss_gen,generator.trainable_variables)\n",
    "        g_optimizer.apply_gradients(zip(grade,generator.trainable_variables))\n",
    "    return loss_dis,loss_gen, generate_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def dis_loss(real,fake,grade,lamda):\n",
    "    loss=tf.reduce_mean(fake)-tf.reduce_mean(real)+lamda*grade\n",
    "    return loss\n",
    "@ tf.function\n",
    "def gen_loss(fake):\n",
    "    return -tf.reduce_mean(fake) \n",
    "@ tf.function\n",
    "def gradien_panalty_loss(grade):\n",
    "    grad_sqr=tf.square(grade)\n",
    "    grad_sqr_sum=tf.reduce_sum(grad_sqr,axis=np.arange(1,len(grad_sqr.shape)))\n",
    "    grad_l2_norm=tf.sqrt(grad_sqr_sum)\n",
    "    grad_penalty=tf.square(1-grad_l2_norm)\n",
    "    return tf.reduce_mean(grad_penalty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Prepare the dataset. We use both the training & test MNIST digits.\n",
    "batch_size = 64\n",
    "# (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "# all_digits = np.concatenate([x_train, x_test])\n",
    "# all_label=keras.utils.to_categorical( np.concatenate([y_train,y_test]))\n",
    "# all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((all_digits,all_label))\n",
    "img_path = glob.glob(r'F:/GAN/faces/*.jpg')\n",
    "dataset1, img_shape, _ = dataset.make_anime_dataset(img_path, batch_size,64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Start epoch 0\n",
      "discriminator loss at step 0: -8.22\n",
      "adversarial loss at step 0: 27.50\n",
      "discriminator loss at step 200: -8.61\n",
      "adversarial loss at step 200: 50.62\n",
      "discriminator loss at step 400: -9.01\n",
      "adversarial loss at step 400: 34.47\n",
      "discriminator loss at step 600: -8.59\n",
      "adversarial loss at step 600: 31.77\n",
      "discriminator loss at step 800: -9.50\n",
      "adversarial loss at step 800: 48.99\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./face_dis\\assets\n",
      "INFO:tensorflow:Assets written to: ./face_gen\\assets\n",
      "\n",
      "Start epoch 1\n",
      "discriminator loss at step 0: -9.22\n",
      "adversarial loss at step 0: 49.84\n",
      "discriminator loss at step 200: -7.98\n",
      "adversarial loss at step 200: 46.42\n",
      "discriminator loss at step 400: -8.74\n",
      "adversarial loss at step 400: 44.96\n",
      "discriminator loss at step 600: -9.68\n",
      "adversarial loss at step 600: 33.60\n",
      "discriminator loss at step 800: -9.17\n",
      "adversarial loss at step 800: 54.10\n",
      "\n",
      "Start epoch 2\n",
      "discriminator loss at step 0: -9.23\n",
      "adversarial loss at step 0: 49.51\n",
      "discriminator loss at step 200: -9.15\n",
      "adversarial loss at step 200: 51.38\n",
      "discriminator loss at step 400: -8.43\n",
      "adversarial loss at step 400: 34.17\n",
      "discriminator loss at step 600: -8.36\n",
      "adversarial loss at step 600: 48.09\n",
      "discriminator loss at step 800: -8.61\n",
      "adversarial loss at step 800: 50.47\n",
      "\n",
      "Start epoch 3\n",
      "discriminator loss at step 0: -8.36\n",
      "adversarial loss at step 0: 46.32\n",
      "discriminator loss at step 200: -8.54\n",
      "adversarial loss at step 200: 36.41\n",
      "discriminator loss at step 400: -8.82\n",
      "adversarial loss at step 400: 46.38\n",
      "discriminator loss at step 600: -9.44\n",
      "adversarial loss at step 600: 34.84\n",
      "discriminator loss at step 800: -8.37\n",
      "adversarial loss at step 800: 44.73\n",
      "\n",
      "Start epoch 4\n",
      "discriminator loss at step 0: -8.54\n",
      "adversarial loss at step 0: 50.25\n",
      "discriminator loss at step 200: -7.87\n",
      "adversarial loss at step 200: 40.40\n",
      "discriminator loss at step 400: -8.59\n",
      "adversarial loss at step 400: 57.00\n",
      "discriminator loss at step 600: -7.59\n",
      "adversarial loss at step 600: 41.24\n",
      "discriminator loss at step 800: -8.35\n",
      "adversarial loss at step 800: 48.56\n",
      "\n",
      "Start epoch 5\n",
      "discriminator loss at step 0: -8.36\n",
      "adversarial loss at step 0: 44.72\n",
      "discriminator loss at step 200: -7.21\n",
      "adversarial loss at step 200: 54.36\n",
      "discriminator loss at step 400: -7.70\n",
      "adversarial loss at step 400: 41.81\n",
      "discriminator loss at step 600: -9.21\n",
      "adversarial loss at step 600: 59.39\n",
      "discriminator loss at step 800: -8.66\n",
      "adversarial loss at step 800: 61.49\n",
      "\n",
      "Start epoch 6\n",
      "discriminator loss at step 0: -9.97\n",
      "adversarial loss at step 0: 70.09\n",
      "discriminator loss at step 200: -8.96\n",
      "adversarial loss at step 200: 41.58\n",
      "discriminator loss at step 400: -9.36\n",
      "adversarial loss at step 400: 39.31\n",
      "discriminator loss at step 600: -8.99\n",
      "adversarial loss at step 600: 51.97\n",
      "discriminator loss at step 800: -9.24\n",
      "adversarial loss at step 800: 54.06\n",
      "\n",
      "Start epoch 7\n",
      "discriminator loss at step 0: -8.10\n",
      "adversarial loss at step 0: 52.11\n",
      "discriminator loss at step 200: -8.37\n",
      "adversarial loss at step 200: 43.20\n",
      "discriminator loss at step 400: -8.30\n",
      "adversarial loss at step 400: 51.99\n",
      "discriminator loss at step 600: -9.08\n",
      "adversarial loss at step 600: 43.85\n",
      "discriminator loss at step 800: -7.80\n",
      "adversarial loss at step 800: 47.23\n",
      "\n",
      "Start epoch 8\n",
      "discriminator loss at step 0: -7.78\n",
      "adversarial loss at step 0: 47.00\n",
      "discriminator loss at step 200: -8.37\n",
      "adversarial loss at step 200: 42.75\n",
      "discriminator loss at step 400: -8.56\n",
      "adversarial loss at step 400: 49.94\n",
      "discriminator loss at step 600: -7.60\n",
      "adversarial loss at step 600: 49.45\n",
      "discriminator loss at step 800: -7.76\n",
      "adversarial loss at step 800: 52.88\n",
      "\n",
      "Start epoch 9\n",
      "discriminator loss at step 0: -8.13\n",
      "adversarial loss at step 0: 53.09\n",
      "discriminator loss at step 200: -10.93\n",
      "adversarial loss at step 200: 42.65\n",
      "discriminator loss at step 400: -9.63\n",
      "adversarial loss at step 400: 53.46\n",
      "discriminator loss at step 600: -8.88\n",
      "adversarial loss at step 600: 44.92\n",
      "discriminator loss at step 800: -8.72\n",
      "adversarial loss at step 800: 49.42\n",
      "\n",
      "Start epoch 10\n",
      "discriminator loss at step 0: -8.34\n",
      "adversarial loss at step 0: 42.22\n",
      "discriminator loss at step 200: -9.30\n",
      "adversarial loss at step 200: 39.55\n",
      "discriminator loss at step 400: -8.61\n",
      "adversarial loss at step 400: 52.15\n",
      "discriminator loss at step 600: -7.78\n",
      "adversarial loss at step 600: 61.64\n",
      "discriminator loss at step 800: -8.18\n",
      "adversarial loss at step 800: 46.15\n",
      "\n",
      "Start epoch 11\n",
      "discriminator loss at step 0: -8.68\n",
      "adversarial loss at step 0: 40.96\n",
      "discriminator loss at step 200: -8.81\n",
      "adversarial loss at step 200: 44.70\n",
      "discriminator loss at step 400: -7.54\n",
      "adversarial loss at step 400: 49.61\n",
      "discriminator loss at step 600: -8.15\n",
      "adversarial loss at step 600: 44.99\n",
      "discriminator loss at step 800: -8.52\n",
      "adversarial loss at step 800: 44.60\n",
      "\n",
      "Start epoch 12\n",
      "discriminator loss at step 0: -8.72\n",
      "adversarial loss at step 0: 40.67\n",
      "discriminator loss at step 200: -8.21\n",
      "adversarial loss at step 200: 45.13\n",
      "discriminator loss at step 400: -8.26\n",
      "adversarial loss at step 400: 49.66\n",
      "discriminator loss at step 600: -8.61\n",
      "adversarial loss at step 600: 40.94\n",
      "discriminator loss at step 800: -9.07\n",
      "adversarial loss at step 800: 53.73\n",
      "\n",
      "Start epoch 13\n",
      "discriminator loss at step 0: -8.52\n",
      "adversarial loss at step 0: 54.42\n",
      "discriminator loss at step 200: -8.94\n",
      "adversarial loss at step 200: 44.06\n",
      "discriminator loss at step 400: -7.31\n",
      "adversarial loss at step 400: 52.02\n",
      "discriminator loss at step 600: -7.52\n",
      "adversarial loss at step 600: 47.17\n",
      "discriminator loss at step 800: -9.07\n",
      "adversarial loss at step 800: 49.26\n",
      "\n",
      "Start epoch 14\n",
      "discriminator loss at step 0: -8.09\n",
      "adversarial loss at step 0: 47.51\n",
      "discriminator loss at step 200: -9.06\n",
      "adversarial loss at step 200: 56.02\n",
      "discriminator loss at step 400: -8.20\n",
      "adversarial loss at step 400: 44.60\n",
      "discriminator loss at step 600: -9.43\n",
      "adversarial loss at step 600: 53.13\n",
      "discriminator loss at step 800: -7.49\n",
      "adversarial loss at step 800: 49.51\n",
      "\n",
      "Start epoch 15\n",
      "discriminator loss at step 0: -9.08\n",
      "adversarial loss at step 0: 58.14\n",
      "discriminator loss at step 200: -8.62\n",
      "adversarial loss at step 200: 53.92\n",
      "discriminator loss at step 400: -7.86\n",
      "adversarial loss at step 400: 51.30\n",
      "discriminator loss at step 600: -7.20\n",
      "adversarial loss at step 600: 46.80\n",
      "discriminator loss at step 800: -9.23\n",
      "adversarial loss at step 800: 43.93\n",
      "\n",
      "Start epoch 16\n",
      "discriminator loss at step 0: -7.72\n",
      "adversarial loss at step 0: 43.47\n",
      "discriminator loss at step 200: -7.88\n",
      "adversarial loss at step 200: 47.26\n",
      "discriminator loss at step 400: -8.35\n",
      "adversarial loss at step 400: 57.75\n",
      "discriminator loss at step 600: -9.83\n",
      "adversarial loss at step 600: 58.07\n",
      "discriminator loss at step 800: -9.50\n",
      "adversarial loss at step 800: 47.42\n",
      "\n",
      "Start epoch 17\n",
      "discriminator loss at step 0: -8.86\n",
      "adversarial loss at step 0: 56.45\n",
      "discriminator loss at step 200: -9.00\n",
      "adversarial loss at step 200: 48.47\n",
      "discriminator loss at step 400: -8.42\n",
      "adversarial loss at step 400: 56.51\n",
      "discriminator loss at step 600: -7.22\n",
      "adversarial loss at step 600: 42.60\n",
      "discriminator loss at step 800: -8.56\n",
      "adversarial loss at step 800: 47.00\n",
      "\n",
      "Start epoch 18\n",
      "discriminator loss at step 0: -8.47\n",
      "adversarial loss at step 0: 47.54\n",
      "discriminator loss at step 200: -7.76\n",
      "adversarial loss at step 200: 50.59\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b4629fc1d044>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# rand_label1=keras.utils.to_categorical(np.random.randint(10,size=(batch_size,1)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# tf.random.set_seed(int(time.time()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0md_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerated_images\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;31m# print(real_images.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Logging.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 2000       # In practice you need at least 20 epochs to generate nice digits.\n",
    "save_dir = \"./\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart epoch\", epoch)\n",
    "    dataset1=dataset1.shuffle(1024)\n",
    "    for step, real_images in enumerate(dataset1):\n",
    "        # break\n",
    "        # Train the discriminator & generator on one batch of real images.\n",
    "        # rand_label1=keras.utils.to_categorical(np.random.randint(10,size=(batch_size,1)))\n",
    "        # tf.random.set_seed(int(time.time()))\n",
    "        d_loss, g_loss, generated_images= train_step(real_images)\n",
    "        # print(real_images.shape)\n",
    "        # Logging.\n",
    "        if step % 200 == 0:\n",
    "            # Print metrics\n",
    "            print(\"discriminator loss at step %d: %.2f\" % (step, d_loss))\n",
    "            print(\"adversarial loss at step %d: %.2f\" % (step, g_loss))\n",
    "\n",
    "            # Save one generated image\n",
    "            img = tf.keras.preprocessing.image.array_to_img(\n",
    "                generated_images[0] * 255.0, scale=False\n",
    "            )\n",
    "            img.save(os.path.join(save_dir, \"generated_img_wgan_\" + str(step) + \".png\"))\n",
    "        #     # print(np.argmax(rand_label1,axis=-1)[0])\n",
    "        # # To limit execution time we stop after 10 steps.\n",
    "        # # Remove the lines below to actually train the model!\n",
    "        # # if step > 10:\n",
    "        # #     break\n",
    "    if epoch%50==0:\n",
    "       discriminator.save(\"./face_dis\")\n",
    "       generator.save(\"./face_gen\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure()\n",
    "# for i in range(1,17):\n",
    "#     plt.subplot(4,4,i)\n",
    "#     plt.imshow(next(iter(dataset1))[i,...])\n",
    "a=next(iter(dataset1))[i,...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.Variable([[1,2],[2,3]])\n",
    "b=tf.Variable([[2],[3]])\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.GradientTape() as tape1:\n",
    "    with tf.GradientTape() as tape2: \n",
    "        random_vector=tf.random.normal(shape=[real_images.shape[0],latent_dim])\n",
    "        generate_image_1=generator(random_vector)\n",
    "        alph=tf.random.normal(shape=[real_images.shape[0],1,1,1])\n",
    "        generate_image_2=alph*real_images+(1-alph)*generate_image_1\n",
    "        out_real=discriminator(real_images)\n",
    "        out_gen_1=discriminator(generate_image_1)\n",
    "        out_gen_2=discriminator(generate_image_2)\n",
    "    grade_1=tape2.gradient(out_gen_2,generate_image_2)\n",
    "    grade_l2=gradien_panalty_loss(grade_1)\n",
    "    loss_dis=dis_loss(out_real,out_gen_1,grade_l2,10)\n",
    "grade_2=tape1.gradient(loss_dis,discriminator.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.mkdir(\"./face_dis2\")\n",
    "os.mkdir(\"./face_gen2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}