{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tf2.0': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9db1de8bbe4618aac8c0dc2f33b2605f1fcbaac7d29e95e578fa6f5b02c8cb82"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator2 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 2)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "input1=keras.Input([28,28,1])\n",
    "input2=keras.Input([10,])\n",
    "net=keras.layers.Dense(128)(input2)\n",
    "net=keras.layers.LeakyReLU(0.2)(net)\n",
    "net=keras.layers.Dense(28*28)(net)\n",
    "net=keras.layers.Reshape((28,28,1))(net)\n",
    "net=keras.layers.concatenate([input1,net])\n",
    "out=discriminator2(net)\n",
    "discriminator=keras.Model(inputs=[input1,input2],outputs=out)\n",
    "latent_dim = 32\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim+10,)),\n",
    "        # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
    "        layers.Dense(7 * 7 * 128),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((7, 7, 128)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128,4,1,padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128,4,1,padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate one optimizer for the discriminator and another for the generator.\n",
    "d_optimizer = keras.optimizers.Adam(learning_rate=0.00008)\n",
    "g_optimizer = keras.optimizers.Adam(learning_rate=0.00004)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(real_images,true_label,random_label0):\n",
    "    # Sample random points in the latent space\n",
    "    true_label=tf.cast(true_label,tf.float32)\n",
    "    tf.random.set_seed(int(time.time()))\n",
    "    np.random.seed(int(time.time()))\n",
    "\n",
    "    random_latent_vectors = tf.random.normal(shape=(real_images.shape[0], latent_dim))\n",
    "    # 随机类别\n",
    "    random_label1=tf.random.shuffle(random_label0)\n",
    "    random_latent_vectors=tf.concat([random_latent_vectors,random_label1],axis=-1)\n",
    "\n",
    "    # Decode them to fake images\n",
    "    generated_images = generator(random_latent_vectors)\n",
    "    # Combine them with real images，最后为类别打乱组\n",
    "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "   \n",
    "    # Assemble labels discriminating real from fake images\n",
    "    # real:0 fake:1\n",
    "    labels = tf.concat(\n",
    "        [tf.ones((real_images.shape[0], 1)), tf.zeros((real_images.shape[0], 1))], axis=0\n",
    "    )\n",
    "    # Add random noise to the labels - important trick!\n",
    "    labels += 0.05 * tf.random.uniform(labels.shape)\n",
    "   \n",
    "    # 类别信息输入\n",
    "    class_layer=tf.concat([random_label1,true_label],axis=0)\n",
    "    # class_layer=tf.reshape(class_layer,[class_layer.shape[0],1,1,10])\n",
    "    # class_layer=tf.tile(class_layer,[1,28,28,1])\n",
    "    # class_layer=tf.concat([combined_images,class_layer],axis=-1)\n",
    "    for i in range(5):\n",
    "    # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = discriminator([combined_images,class_layer])\n",
    "            d_loss = loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, discriminator.trainable_weights)\n",
    "        d_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "    \n",
    "    # 打乱类别\n",
    "    random_latent_vectors = tf.random.normal(shape=(real_images.shape[0], latent_dim))\n",
    "    # 随机类别\n",
    "    random_label1=tf.random.shuffle(random_label0)\n",
    "    random_latent_vectors=tf.concat([random_latent_vectors,random_label1],axis=-1)\n",
    "    # Decode them to fake images\n",
    "    generated_images = generator(random_latent_vectors)\n",
    "    # Combine them with real images，最后为类别打乱组\n",
    "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "    f_label=tf.random.shuffle(true_label)\n",
    "    label_f=tf.abs(tf.cast(tf.equal(tf.argmax(true_label,axis=-1),tf.argmax(f_label,axis=-1)),dtype=tf.float32)-1)\n",
    "    combind_label=tf.concat([rand_label1,f_label],axis=0)\n",
    "    # class_layer=tf.tile(tf.reshape(combind_label,[combind_label.shape[0],1,1,10]),[1,28,28,1])\n",
    "    # class_layer=tf.concat([combined_images,class_layer],axis=-1)\n",
    "    for i in range(5):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = discriminator([combined_images,combind_label])\n",
    "            d_loss = loss_fn(tf.concat([tf.ones(real_images.shape[0]),label_f],axis=0), predictions)\n",
    "        grads = tape.gradient(d_loss, discriminator.trainable_weights)\n",
    "        d_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "    \n",
    "    # Sample random points in the latent space\n",
    "    random_latent_vectors = tf.random.normal(shape=(real_images.shape[0], latent_dim))\n",
    "    random_label=tf.random.shuffle(random_label0)\n",
    "    random_latent_vectors=tf.concat([random_latent_vectors,random_label],axis=-1)\n",
    "\n",
    "    # Assemble labels that say \"all real images\"\n",
    "    # real:0\n",
    "    misleading_labels = tf.zeros((real_images.shape[0], 1))\n",
    "    # class_layer=tf.tile(tf.reshape(random_label,[batch_size,1,1,10]),[1,28,28,1])\n",
    "    # Train the generator (note that we should *not* update the weights\n",
    "    # of the discriminator)!\n",
    "    for i in range(20):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = discriminator([ generator(random_latent_vectors),random_label])\n",
    "            g_loss = loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, generator.trainable_weights)\n",
    "        g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
    "    return d_loss, g_loss, generated_images,random_label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Prepare the dataset. We use both the training & test MNIST digits.\n",
    "batch_size = 256\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_label=keras.utils.to_categorical( np.concatenate([y_train,y_test]))\n",
    "all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_digits,all_label))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def W_loss(real,fake,grade,lamda):\n",
    "    loss=tf.reduce_mean(real,axis=0)-tf.reduce_mean(fake,axis=0)\n",
    "    keras.regularizers.l2(1)(gra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "74\n",
      "5\n",
      "discriminator loss at step 20: 0.08\n",
      "adversarial loss at step 20: 1.42\n",
      "4\n",
      "discriminator loss at step 40: 0.06\n",
      "adversarial loss at step 40: 1.19\n",
      "1\n",
      "discriminator loss at step 60: 0.09\n",
      "adversarial loss at step 60: 1.54\n",
      "3\n",
      "discriminator loss at step 80: 0.09\n",
      "adversarial loss at step 80: 1.62\n",
      "3\n",
      "discriminator loss at step 100: 0.07\n",
      "adversarial loss at step 100: 1.54\n",
      "7\n",
      "discriminator loss at step 120: 0.13\n",
      "adversarial loss at step 120: 1.09\n",
      "9\n",
      "discriminator loss at step 140: 0.11\n",
      "adversarial loss at step 140: 0.80\n",
      "4\n",
      "discriminator loss at step 160: 0.09\n",
      "adversarial loss at step 160: 1.27\n",
      "1\n",
      "discriminator loss at step 180: 0.11\n",
      "adversarial loss at step 180: 1.52\n",
      "1\n",
      "discriminator loss at step 200: 0.06\n",
      "adversarial loss at step 200: 1.44\n",
      "7\n",
      "discriminator loss at step 220: 0.08\n",
      "adversarial loss at step 220: 1.45\n",
      "1\n",
      "discriminator loss at step 240: 0.09\n",
      "adversarial loss at step 240: 1.41\n",
      "5\n",
      "discriminator loss at step 260: 0.09\n",
      "adversarial loss at step 260: 1.24\n",
      "5\n",
      "\n",
      "Start epoch 135\n",
      "discriminator loss at step 0: 0.13\n",
      "adversarial loss at step 0: 0.68\n",
      "0\n",
      "discriminator loss at step 20: 0.11\n",
      "adversarial loss at step 20: 1.07\n",
      "2\n",
      "discriminator loss at step 40: 0.12\n",
      "adversarial loss at step 40: 1.27\n",
      "3\n",
      "discriminator loss at step 60: 0.10\n",
      "adversarial loss at step 60: 1.13\n",
      "8\n",
      "discriminator loss at step 80: 0.10\n",
      "adversarial loss at step 80: 1.32\n",
      "0\n",
      "discriminator loss at step 100: 0.09\n",
      "adversarial loss at step 100: 0.89\n",
      "8\n",
      "discriminator loss at step 120: 0.11\n",
      "adversarial loss at step 120: 0.74\n",
      "4\n",
      "discriminator loss at step 140: 0.12\n",
      "adversarial loss at step 140: 0.82\n",
      "9\n",
      "discriminator loss at step 160: 0.08\n",
      "adversarial loss at step 160: 1.29\n",
      "0\n",
      "discriminator loss at step 180: 0.07\n",
      "adversarial loss at step 180: 1.50\n",
      "5\n",
      "discriminator loss at step 200: 0.07\n",
      "adversarial loss at step 200: 1.34\n",
      "2\n",
      "discriminator loss at step 220: 0.09\n",
      "adversarial loss at step 220: 1.29\n",
      "9\n",
      "discriminator loss at step 240: 0.12\n",
      "adversarial loss at step 240: 0.84\n",
      "2\n",
      "discriminator loss at step 260: 0.10\n",
      "adversarial loss at step 260: 1.38\n",
      "5\n",
      "\n",
      "Start epoch 136\n",
      "discriminator loss at step 0: 0.16\n",
      "adversarial loss at step 0: 0.48\n",
      "5\n",
      "discriminator loss at step 20: 0.09\n",
      "adversarial loss at step 20: 1.32\n",
      "5\n",
      "discriminator loss at step 40: 0.10\n",
      "adversarial loss at step 40: 0.79\n",
      "0\n",
      "discriminator loss at step 60: 0.09\n",
      "adversarial loss at step 60: 1.10\n",
      "3\n",
      "discriminator loss at step 80: 0.07\n",
      "adversarial loss at step 80: 1.32\n",
      "5\n",
      "discriminator loss at step 100: 0.13\n",
      "adversarial loss at step 100: 1.22\n",
      "9\n",
      "discriminator loss at step 120: 0.09\n",
      "adversarial loss at step 120: 1.27\n",
      "1\n",
      "discriminator loss at step 140: 0.09\n",
      "adversarial loss at step 140: 1.23\n",
      "2\n",
      "discriminator loss at step 160: 0.09\n",
      "adversarial loss at step 160: 1.36\n",
      "4\n",
      "discriminator loss at step 180: 0.08\n",
      "adversarial loss at step 180: 1.38\n",
      "7\n",
      "discriminator loss at step 200: 0.09\n",
      "adversarial loss at step 200: 1.69\n",
      "9\n",
      "discriminator loss at step 220: 0.12\n",
      "adversarial loss at step 220: 1.84\n",
      "9\n",
      "discriminator loss at step 240: 0.11\n",
      "adversarial loss at step 240: 1.16\n",
      "7\n",
      "discriminator loss at step 260: 0.07\n",
      "adversarial loss at step 260: 1.20\n",
      "3\n",
      "\n",
      "Start epoch 137\n",
      "discriminator loss at step 0: 0.18\n",
      "adversarial loss at step 0: 0.46\n",
      "7\n",
      "discriminator loss at step 20: 0.11\n",
      "adversarial loss at step 20: 1.03\n",
      "6\n",
      "discriminator loss at step 40: 0.10\n",
      "adversarial loss at step 40: 1.18\n",
      "1\n",
      "discriminator loss at step 60: 0.12\n",
      "adversarial loss at step 60: 1.11\n",
      "4\n",
      "discriminator loss at step 80: 0.08\n",
      "adversarial loss at step 80: 1.24\n",
      "6\n",
      "discriminator loss at step 100: 0.08\n",
      "adversarial loss at step 100: 1.36\n",
      "9\n",
      "discriminator loss at step 120: 0.08\n",
      "adversarial loss at step 120: 1.25\n",
      "2\n",
      "discriminator loss at step 140: 0.11\n",
      "adversarial loss at step 140: 1.08\n",
      "0\n",
      "discriminator loss at step 160: 0.07\n",
      "adversarial loss at step 160: 1.50\n",
      "6\n",
      "discriminator loss at step 180: 0.11\n",
      "adversarial loss at step 180: 1.12\n",
      "8\n",
      "discriminator loss at step 200: 0.08\n",
      "adversarial loss at step 200: 1.58\n",
      "8\n",
      "discriminator loss at step 220: 0.09\n",
      "adversarial loss at step 220: 1.97\n",
      "8\n",
      "discriminator loss at step 240: 0.09\n",
      "adversarial loss at step 240: 1.21\n",
      "4\n",
      "discriminator loss at step 260: 0.08\n",
      "adversarial loss at step 260: 1.18\n",
      "2\n",
      "\n",
      "Start epoch 138\n",
      "discriminator loss at step 0: 0.15\n",
      "adversarial loss at step 0: 0.41\n",
      "0\n",
      "discriminator loss at step 20: 0.07\n",
      "adversarial loss at step 20: 1.13\n",
      "5\n",
      "discriminator loss at step 40: 0.09\n",
      "adversarial loss at step 40: 1.57\n",
      "4\n",
      "discriminator loss at step 60: 0.07\n",
      "adversarial loss at step 60: 1.04\n",
      "7\n",
      "discriminator loss at step 80: 0.10\n",
      "adversarial loss at step 80: 1.27\n",
      "8\n",
      "discriminator loss at step 100: 0.06\n",
      "adversarial loss at step 100: 1.19\n",
      "5\n",
      "discriminator loss at step 120: 0.11\n",
      "adversarial loss at step 120: 0.81\n",
      "9\n",
      "discriminator loss at step 140: 0.10\n",
      "adversarial loss at step 140: 0.76\n",
      "9\n",
      "discriminator loss at step 160: 0.09\n",
      "adversarial loss at step 160: 1.32\n",
      "5\n",
      "discriminator loss at step 180: 0.13\n",
      "adversarial loss at step 180: 1.03\n",
      "5\n",
      "discriminator loss at step 200: 0.08\n",
      "adversarial loss at step 200: 1.18\n",
      "9\n",
      "discriminator loss at step 220: 0.08\n",
      "adversarial loss at step 220: 1.55\n",
      "3\n",
      "discriminator loss at step 240: 0.10\n",
      "adversarial loss at step 240: 1.15\n",
      "5\n",
      "discriminator loss at step 260: 0.08\n",
      "adversarial loss at step 260: 1.16\n",
      "9\n",
      "\n",
      "Start epoch 139\n",
      "discriminator loss at step 0: 0.16\n",
      "adversarial loss at step 0: 0.30\n",
      "2\n",
      "discriminator loss at step 20: 0.09\n",
      "adversarial loss at step 20: 1.04\n",
      "6\n",
      "discriminator loss at step 40: 0.10\n",
      "adversarial loss at step 40: 1.26\n",
      "6\n",
      "discriminator loss at step 60: 0.10\n",
      "adversarial loss at step 60: 1.27\n",
      "6\n",
      "discriminator loss at step 80: 0.08\n",
      "adversarial loss at step 80: 1.19\n",
      "9\n",
      "discriminator loss at step 100: 0.08\n",
      "adversarial loss at step 100: 1.09\n",
      "4\n",
      "discriminator loss at step 120: 0.08\n",
      "adversarial loss at step 120: 1.75\n",
      "9\n",
      "discriminator loss at step 140: 0.10\n",
      "adversarial loss at step 140: 1.42\n",
      "1\n",
      "discriminator loss at step 160: 0.14\n",
      "adversarial loss at step 160: 1.31\n",
      "2\n",
      "discriminator loss at step 180: 0.08\n",
      "adversarial loss at step 180: 1.78\n",
      "8\n",
      "discriminator loss at step 200: 0.07\n",
      "adversarial loss at step 200: 1.37\n",
      "8\n",
      "discriminator loss at step 220: 0.07\n",
      "adversarial loss at step 220: 1.89\n",
      "3\n",
      "discriminator loss at step 240: 0.09\n",
      "adversarial loss at step 240: 1.22\n",
      "8\n",
      "discriminator loss at step 260: 0.08\n",
      "adversarial loss at step 260: 0.86\n",
      "4\n",
      "\n",
      "Start epoch 140\n",
      "discriminator loss at step 0: 0.21\n",
      "adversarial loss at step 0: 0.33\n",
      "0\n",
      "discriminator loss at step 20: 0.11\n",
      "adversarial loss at step 20: 0.83\n",
      "8\n",
      "discriminator loss at step 40: 0.10\n",
      "adversarial loss at step 40: 0.90\n",
      "6\n",
      "discriminator loss at step 60: 0.07\n",
      "adversarial loss at step 60: 1.28\n",
      "3\n",
      "discriminator loss at step 80: 0.11\n",
      "adversarial loss at step 80: 1.60\n",
      "3\n",
      "discriminator loss at step 100: 0.09\n",
      "adversarial loss at step 100: 1.38\n",
      "8\n",
      "discriminator loss at step 120: 0.10\n",
      "adversarial loss at step 120: 1.64\n",
      "1\n",
      "discriminator loss at step 140: 0.07\n",
      "adversarial loss at step 140: 1.58\n",
      "3\n",
      "discriminator loss at step 160: 0.11\n",
      "adversarial loss at step 160: 1.20\n",
      "4\n",
      "discriminator loss at step 180: 0.08\n",
      "adversarial loss at step 180: 1.76\n",
      "8\n",
      "discriminator loss at step 200: 0.09\n",
      "adversarial loss at step 200: 1.45\n",
      "7\n",
      "discriminator loss at step 220: 0.06\n",
      "adversarial loss at step 220: 1.66\n",
      "8\n",
      "discriminator loss at step 240: 0.08\n",
      "adversarial loss at step 240: 1.39\n",
      "6\n",
      "discriminator loss at step 260: 0.08\n",
      "adversarial loss at step 260: 1.09\n",
      "7\n",
      "\n",
      "Start epoch 141\n",
      "discriminator loss at step 0: 0.14\n",
      "adversarial loss at step 0: 0.38\n",
      "6\n",
      "discriminator loss at step 20: 0.10\n",
      "adversarial loss at step 20: 1.17\n",
      "8\n",
      "discriminator loss at step 40: 0.12\n",
      "adversarial loss at step 40: 0.67\n",
      "0\n",
      "discriminator loss at step 60: 0.11\n",
      "adversarial loss at step 60: 1.03\n",
      "0\n",
      "discriminator loss at step 80: 0.09\n",
      "adversarial loss at step 80: 1.34\n",
      "4\n",
      "discriminator loss at step 100: 0.11\n",
      "adversarial loss at step 100: 1.04\n",
      "9\n",
      "discriminator loss at step 120: 0.12\n",
      "adversarial loss at step 120: 1.17\n",
      "9\n",
      "discriminator loss at step 140: 0.09\n",
      "adversarial loss at step 140: 1.45\n",
      "6\n",
      "discriminator loss at step 160: 0.08\n",
      "adversarial loss at step 160: 1.48\n",
      "7\n",
      "discriminator loss at step 180: 0.09\n",
      "adversarial loss at step 180: 1.72\n",
      "6\n",
      "discriminator loss at step 200: 0.09\n",
      "adversarial loss at step 200: 1.20\n",
      "2\n",
      "discriminator loss at step 220: 0.12\n",
      "adversarial loss at step 220: 1.19\n",
      "0\n",
      "discriminator loss at step 240: 0.11\n",
      "adversarial loss at step 240: 1.17\n",
      "8\n",
      "discriminator loss at step 260: 0.07\n",
      "adversarial loss at step 260: 1.85\n",
      "0\n",
      "\n",
      "Start epoch 142\n",
      "discriminator loss at step 0: 0.16\n",
      "adversarial loss at step 0: 0.63\n",
      "9\n",
      "discriminator loss at step 20: 0.06\n",
      "adversarial loss at step 20: 1.46\n",
      "9\n",
      "discriminator loss at step 40: 0.09\n",
      "adversarial loss at step 40: 1.43\n",
      "6\n",
      "discriminator loss at step 60: 0.13\n",
      "adversarial loss at step 60: 1.30\n",
      "5\n",
      "discriminator loss at step 80: 0.07\n",
      "adversarial loss at step 80: 1.52\n",
      "1\n",
      "discriminator loss at step 100: 0.06\n",
      "adversarial loss at step 100: 1.48\n",
      "7\n",
      "discriminator loss at step 120: 0.09\n",
      "adversarial loss at step 120: 1.19\n",
      "3\n",
      "discriminator loss at step 140: 0.11\n",
      "adversarial loss at step 140: 0.84\n",
      "4\n",
      "discriminator loss at step 160: 0.10\n",
      "adversarial loss at step 160: 1.09\n",
      "7\n",
      "discriminator loss at step 180: 0.11\n",
      "adversarial loss at step 180: 1.79\n",
      "6\n",
      "discriminator loss at step 200: 0.09\n",
      "adversarial loss at step 200: 1.49\n",
      "0\n",
      "discriminator loss at step 220: 0.10\n",
      "adversarial loss at step 220: 0.96\n",
      "7\n",
      "discriminator loss at step 240: 0.10\n",
      "adversarial loss at step 240: 1.09\n",
      "0\n",
      "discriminator loss at step 260: 0.09\n",
      "adversarial loss at step 260: 0.71\n",
      "3\n",
      "\n",
      "Start epoch 143\n",
      "discriminator loss at step 0: 0.17\n",
      "adversarial loss at step 0: 0.37\n",
      "0\n",
      "discriminator loss at step 20: 0.10\n",
      "adversarial loss at step 20: 1.05\n",
      "2\n",
      "discriminator loss at step 40: 0.11\n",
      "adversarial loss at step 40: 1.00\n",
      "0\n",
      "discriminator loss at step 60: 0.09\n",
      "adversarial loss at step 60: 1.34\n",
      "4\n",
      "discriminator loss at step 80: 0.11\n",
      "adversarial loss at step 80: 1.07\n",
      "6\n",
      "discriminator loss at step 100: 0.11\n",
      "adversarial loss at step 100: 1.54\n",
      "0\n",
      "discriminator loss at step 120: 0.10\n",
      "adversarial loss at step 120: 1.15\n",
      "2\n",
      "discriminator loss at step 140: 0.09\n",
      "adversarial loss at step 140: 1.16\n",
      "9\n",
      "discriminator loss at step 160: 0.11\n",
      "adversarial loss at step 160: 1.06\n",
      "0\n",
      "discriminator loss at step 180: 0.09\n",
      "adversarial loss at step 180: 1.50\n",
      "3\n",
      "discriminator loss at step 200: 0.09\n",
      "adversarial loss at step 200: 1.11\n",
      "2\n",
      "discriminator loss at step 220: 0.09\n",
      "adversarial loss at step 220: 1.07\n",
      "2\n",
      "discriminator loss at step 240: 0.07\n",
      "adversarial loss at step 240: 1.27\n",
      "1\n",
      "discriminator loss at step 260: 0.09\n",
      "adversarial loss at step 260: 1.65\n",
      "0\n",
      "\n",
      "Start epoch 144\n",
      "discriminator loss at step 0: 0.10\n",
      "adversarial loss at step 0: 1.18\n",
      "5\n",
      "discriminator loss at step 20: 0.09\n",
      "adversarial loss at step 20: 1.37\n",
      "3\n",
      "discriminator loss at step 40: 0.10\n",
      "adversarial loss at step 40: 1.79\n",
      "3\n",
      "discriminator loss at step 60: 0.08\n",
      "adversarial loss at step 60: 1.13\n",
      "7\n",
      "discriminator loss at step 80: 0.09\n",
      "adversarial loss at step 80: 1.70\n",
      "9\n",
      "discriminator loss at step 100: 0.08\n",
      "adversarial loss at step 100: 1.24\n",
      "8\n",
      "discriminator loss at step 120: 0.12\n",
      "adversarial loss at step 120: 1.30\n",
      "2\n",
      "discriminator loss at step 140: 0.07\n",
      "adversarial loss at step 140: 1.42\n",
      "0\n",
      "discriminator loss at step 160: 0.10\n",
      "adversarial loss at step 160: 1.38\n",
      "8\n",
      "discriminator loss at step 180: 0.07\n",
      "adversarial loss at step 180: 1.47\n",
      "9\n",
      "discriminator loss at step 200: 0.08\n",
      "adversarial loss at step 200: 1.45\n",
      "4\n",
      "discriminator loss at step 220: 0.09\n",
      "adversarial loss at step 220: 1.84\n",
      "8\n",
      "discriminator loss at step 240: 0.10\n",
      "adversarial loss at step 240: 1.17\n",
      "1\n",
      "discriminator loss at step 260: 0.07\n",
      "adversarial loss at step 260: 1.28\n",
      "5\n",
      "\n",
      "Start epoch 145\n",
      "discriminator loss at step 0: 0.13\n",
      "adversarial loss at step 0: 0.55\n",
      "0\n",
      "discriminator loss at step 20: 0.09\n",
      "adversarial loss at step 20: 1.10\n",
      "7\n",
      "discriminator loss at step 40: 0.06\n",
      "adversarial loss at step 40: 1.32\n",
      "1\n",
      "discriminator loss at step 60: 0.10\n",
      "adversarial loss at step 60: 1.18\n",
      "8\n",
      "discriminator loss at step 80: 0.07\n",
      "adversarial loss at step 80: 1.70\n",
      "3\n",
      "discriminator loss at step 100: 0.08\n",
      "adversarial loss at step 100: 1.17\n",
      "3\n",
      "discriminator loss at step 120: 0.08\n",
      "adversarial loss at step 120: 1.60\n",
      "1\n",
      "discriminator loss at step 140: 0.09\n",
      "adversarial loss at step 140: 1.29\n",
      "8\n",
      "discriminator loss at step 160: 0.08\n",
      "adversarial loss at step 160: 1.66\n",
      "8\n",
      "discriminator loss at step 180: 0.07\n",
      "adversarial loss at step 180: 1.42\n",
      "7\n",
      "discriminator loss at step 200: 0.09\n",
      "adversarial loss at step 200: 1.05\n",
      "5\n",
      "discriminator loss at step 220: 0.10\n",
      "adversarial loss at step 220: 1.36\n",
      "9\n",
      "discriminator loss at step 240: 0.10\n",
      "adversarial loss at step 240: 1.48\n",
      "2\n",
      "discriminator loss at step 260: 0.12\n",
      "adversarial loss at step 260: 0.64\n",
      "3\n",
      "\n",
      "Start epoch 146\n",
      "discriminator loss at step 0: 0.16\n",
      "adversarial loss at step 0: 0.54\n",
      "7\n",
      "discriminator loss at step 20: 0.13\n",
      "adversarial loss at step 20: 1.07\n",
      "4\n",
      "discriminator loss at step 40: 0.09\n",
      "adversarial loss at step 40: 1.34\n",
      "9\n",
      "discriminator loss at step 60: 0.06\n",
      "adversarial loss at step 60: 1.47\n",
      "2\n",
      "discriminator loss at step 80: 0.10\n",
      "adversarial loss at step 80: 1.26\n",
      "6\n",
      "discriminator loss at step 100: 0.10\n",
      "adversarial loss at step 100: 1.32\n",
      "7\n",
      "discriminator loss at step 120: 0.11\n",
      "adversarial loss at step 120: 0.66\n",
      "1\n",
      "discriminator loss at step 140: 0.10\n",
      "adversarial loss at step 140: 1.05\n",
      "0\n",
      "discriminator loss at step 160: 0.11\n",
      "adversarial loss at step 160: 1.19\n",
      "2\n",
      "discriminator loss at step 180: 0.09\n",
      "adversarial loss at step 180: 1.15\n",
      "8\n",
      "discriminator loss at step 200: 0.10\n",
      "adversarial loss at step 200: 1.10\n",
      "1\n",
      "discriminator loss at step 220: 0.06\n",
      "adversarial loss at step 220: 1.57\n",
      "6\n",
      "discriminator loss at step 240: 0.09\n",
      "adversarial loss at step 240: 1.42\n",
      "0\n",
      "discriminator loss at step 260: 0.06\n",
      "adversarial loss at step 260: 1.55\n",
      "8\n",
      "\n",
      "Start epoch 147\n",
      "discriminator loss at step 0: 0.19\n",
      "adversarial loss at step 0: 0.48\n",
      "4\n",
      "discriminator loss at step 20: 0.08\n",
      "adversarial loss at step 20: 1.18\n",
      "7\n",
      "discriminator loss at step 40: 0.10\n",
      "adversarial loss at step 40: 0.97\n",
      "3\n",
      "discriminator loss at step 60: 0.08\n",
      "adversarial loss at step 60: 1.47\n",
      "7\n",
      "discriminator loss at step 80: 0.08\n",
      "adversarial loss at step 80: 1.28\n",
      "3\n",
      "discriminator loss at step 100: 0.14\n",
      "adversarial loss at step 100: 0.63\n",
      "7\n",
      "discriminator loss at step 120: 0.10\n",
      "adversarial loss at step 120: 0.81\n",
      "6\n",
      "discriminator loss at step 140: 0.10\n",
      "adversarial loss at step 140: 1.16\n",
      "7\n",
      "discriminator loss at step 160: 0.11\n",
      "adversarial loss at step 160: 0.80\n",
      "6\n",
      "discriminator loss at step 180: 0.11\n",
      "adversarial loss at step 180: 1.18\n",
      "1\n",
      "discriminator loss at step 200: 0.13\n",
      "adversarial loss at step 200: 1.10\n",
      "2\n",
      "discriminator loss at step 220: 0.09\n",
      "adversarial loss at step 220: 1.49\n",
      "5\n",
      "discriminator loss at step 240: 0.08\n",
      "adversarial loss at step 240: 1.35\n",
      "3\n",
      "discriminator loss at step 260: 0.06\n",
      "adversarial loss at step 260: 1.72\n",
      "8\n",
      "\n",
      "Start epoch 148\n",
      "discriminator loss at step 0: 0.18\n",
      "adversarial loss at step 0: 0.30\n",
      "8\n",
      "discriminator loss at step 20: 0.10\n",
      "adversarial loss at step 20: 1.29\n",
      "9\n",
      "discriminator loss at step 40: 0.10\n",
      "adversarial loss at step 40: 1.02\n",
      "6\n",
      "discriminator loss at step 60: 0.12\n",
      "adversarial loss at step 60: 0.77\n",
      "8\n",
      "discriminator loss at step 80: 0.09\n",
      "adversarial loss at step 80: 1.54\n",
      "5\n",
      "discriminator loss at step 100: 0.09\n",
      "adversarial loss at step 100: 1.05\n",
      "0\n",
      "discriminator loss at step 120: 0.11\n",
      "adversarial loss at step 120: 1.16\n",
      "4\n",
      "discriminator loss at step 140: 0.09\n",
      "adversarial loss at step 140: 1.37\n",
      "4\n",
      "discriminator loss at step 160: 0.06\n",
      "adversarial loss at step 160: 1.48\n",
      "6\n",
      "discriminator loss at step 180: 0.11\n",
      "adversarial loss at step 180: 0.78\n",
      "8\n",
      "discriminator loss at step 200: 0.09\n",
      "adversarial loss at step 200: 1.02\n",
      "4\n",
      "discriminator loss at step 220: 0.10\n",
      "adversarial loss at step 220: 1.89\n",
      "3\n",
      "discriminator loss at step 240: 0.08\n",
      "adversarial loss at step 240: 1.07\n",
      "7\n",
      "discriminator loss at step 260: 0.11\n",
      "adversarial loss at step 260: 1.31\n",
      "4\n",
      "\n",
      "Start epoch 149\n",
      "discriminator loss at step 0: 0.17\n",
      "adversarial loss at step 0: 0.41\n",
      "9\n",
      "discriminator loss at step 20: 0.08\n",
      "adversarial loss at step 20: 1.57\n",
      "6\n",
      "discriminator loss at step 40: 0.07\n",
      "adversarial loss at step 40: 1.35\n",
      "0\n",
      "discriminator loss at step 60: 0.10\n",
      "adversarial loss at step 60: 1.31\n",
      "0\n",
      "discriminator loss at step 80: 0.06\n",
      "adversarial loss at step 80: 1.60\n",
      "8\n",
      "discriminator loss at step 100: 0.09\n",
      "adversarial loss at step 100: 1.48\n",
      "4\n",
      "discriminator loss at step 120: 0.11\n",
      "adversarial loss at step 120: 1.19\n",
      "0\n",
      "discriminator loss at step 140: 0.10\n",
      "adversarial loss at step 140: 1.27\n",
      "4\n",
      "discriminator loss at step 160: 0.10\n",
      "adversarial loss at step 160: 1.37\n",
      "0\n",
      "discriminator loss at step 180: 0.08\n",
      "adversarial loss at step 180: 1.29\n",
      "8\n",
      "discriminator loss at step 200: 0.09\n",
      "adversarial loss at step 200: 1.00\n",
      "4\n",
      "discriminator loss at step 220: 0.10\n",
      "adversarial loss at step 220: 1.30\n",
      "3\n",
      "discriminator loss at step 240: 0.10\n",
      "adversarial loss at step 240: 1.31\n",
      "2\n",
      "discriminator loss at step 260: 0.08\n",
      "adversarial loss at step 260: 1.06\n",
      "8\n",
      "\n",
      "Start epoch 150\n",
      "discriminator loss at step 0: 0.17\n",
      "adversarial loss at step 0: 0.61\n",
      "1\n",
      "discriminator loss at step 20: 0.10\n",
      "adversarial loss at step 20: 1.59\n",
      "9\n",
      "discriminator loss at step 40: 0.09\n",
      "adversarial loss at step 40: 1.28\n",
      "1\n",
      "discriminator loss at step 60: 0.12\n",
      "adversarial loss at step 60: 1.28\n",
      "7\n",
      "discriminator loss at step 80: 0.08\n",
      "adversarial loss at step 80: 1.33\n",
      "3\n",
      "discriminator loss at step 100: 0.08\n",
      "adversarial loss at step 100: 1.55\n",
      "7\n",
      "discriminator loss at step 120: 0.09\n",
      "adversarial loss at step 120: 1.24\n",
      "3\n",
      "discriminator loss at step 140: 0.10\n",
      "adversarial loss at step 140: 1.48\n",
      "2\n",
      "discriminator loss at step 160: 0.08\n",
      "adversarial loss at step 160: 1.53\n",
      "2\n",
      "discriminator loss at step 180: 0.09\n",
      "adversarial loss at step 180: 1.03\n",
      "1\n",
      "discriminator loss at step 200: 0.09\n",
      "adversarial loss at step 200: 1.21\n",
      "9\n",
      "discriminator loss at step 220: 0.11\n",
      "adversarial loss at step 220: 0.76\n",
      "2\n",
      "discriminator loss at step 240: 0.10\n",
      "adversarial loss at step 240: 1.13\n",
      "3\n",
      "discriminator loss at step 260: 0.08\n",
      "adversarial loss at step 260: 0.99\n",
      "3\n",
      "\n",
      "Start epoch 151\n",
      "discriminator loss at step 0: 0.15\n",
      "adversarial loss at step 0: 0.68\n",
      "7\n",
      "discriminator loss at step 20: 0.08\n",
      "adversarial loss at step 20: 1.06\n",
      "5\n",
      "discriminator loss at step 40: 0.09\n",
      "adversarial loss at step 40: 0.93\n",
      "9\n",
      "discriminator loss at step 60: 0.08\n",
      "adversarial loss at step 60: 1.08\n",
      "8\n",
      "discriminator loss at step 80: 0.06\n",
      "adversarial loss at step 80: 1.59\n",
      "1\n",
      "discriminator loss at step 100: 0.11\n",
      "adversarial loss at step 100: 1.41\n",
      "5\n",
      "discriminator loss at step 120: 0.10\n",
      "adversarial loss at step 120: 1.31\n",
      "7\n",
      "discriminator loss at step 140: 0.09\n",
      "adversarial loss at step 140: 1.06\n",
      "5\n",
      "discriminator loss at step 160: 0.10\n",
      "adversarial loss at step 160: 0.81\n",
      "7\n",
      "discriminator loss at step 180: 0.10\n",
      "adversarial loss at step 180: 1.24\n",
      "2\n",
      "discriminator loss at step 200: 0.12\n",
      "adversarial loss at step 200: 1.07\n",
      "7\n",
      "discriminator loss at step 220: 0.08\n",
      "adversarial loss at step 220: 1.11\n",
      "4\n",
      "discriminator loss at step 240: 0.09\n",
      "adversarial loss at step 240: 1.42\n",
      "3\n",
      "discriminator loss at step 260: 0.08\n",
      "adversarial loss at step 260: 1.32\n",
      "7\n",
      "\n",
      "Start epoch 152\n",
      "discriminator loss at step 0: 0.11\n",
      "adversarial loss at step 0: 0.75\n",
      "6\n",
      "discriminator loss at step 20: 0.09\n",
      "adversarial loss at step 20: 1.26\n",
      "7\n",
      "discriminator loss at step 40: 0.09\n",
      "adversarial loss at step 40: 0.99\n",
      "7\n",
      "discriminator loss at step 60: 0.09\n",
      "adversarial loss at step 60: 1.24\n",
      "4\n",
      "discriminator loss at step 80: 0.11\n",
      "adversarial loss at step 80: 1.45\n",
      "1\n",
      "discriminator loss at step 100: 0.12\n",
      "adversarial loss at step 100: 1.00\n",
      "5\n",
      "discriminator loss at step 120: 0.13\n",
      "adversarial loss at step 120: 1.04\n",
      "8\n",
      "discriminator loss at step 140: 0.09\n",
      "adversarial loss at step 140: 0.94\n",
      "8\n",
      "discriminator loss at step 160: 0.07\n",
      "adversarial loss at step 160: 1.16\n",
      "6\n",
      "discriminator loss at step 180: 0.12\n",
      "adversarial loss at step 180: 1.27\n",
      "2\n",
      "discriminator loss at step 200: 0.11\n",
      "adversarial loss at step 200: 0.98\n",
      "8\n",
      "discriminator loss at step 220: 0.10\n",
      "adversarial loss at step 220: 0.79\n",
      "9\n",
      "discriminator loss at step 240: 0.12\n",
      "adversarial loss at step 240: 0.65\n",
      "0\n",
      "discriminator loss at step 260: 0.10\n",
      "adversarial loss at step 260: 1.35\n",
      "9\n",
      "\n",
      "Start epoch 153\n",
      "discriminator loss at step 0: 0.18\n",
      "adversarial loss at step 0: 0.50\n",
      "4\n",
      "discriminator loss at step 20: 0.09\n",
      "adversarial loss at step 20: 1.01\n",
      "0\n",
      "discriminator loss at step 40: 0.12\n",
      "adversarial loss at step 40: 1.09\n",
      "1\n",
      "discriminator loss at step 60: 0.11\n",
      "adversarial loss at step 60: 1.19\n",
      "5\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-90789fa5d94b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# Train the discriminator & generator on one batch of real images.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mrand_label1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0md_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerated_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrand_label1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrand_label1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Logging.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 200       # In practice you need at least 20 epochs to generate nice digits.\n",
    "save_dir = \"./\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart epoch\", epoch)\n",
    "\n",
    "    for step, [real_images,label] in enumerate(dataset):\n",
    "        # break\n",
    "        # Train the discriminator & generator on one batch of real images.\n",
    "        rand_label1=keras.utils.to_categorical(np.random.randint(10,size=(batch_size,1)))\n",
    "        d_loss, g_loss, generated_images,rand_label1= train_step(real_images,label,rand_label1)\n",
    "\n",
    "        # Logging.\n",
    "        if step % 20 == 0:\n",
    "            # Print metrics\n",
    "            print(\"discriminator loss at step %d: %.2f\" % (step, d_loss))\n",
    "            print(\"adversarial loss at step %d: %.2f\" % (step, g_loss))\n",
    "\n",
    "            # Save one generated image\n",
    "            img = tf.keras.preprocessing.image.array_to_img(\n",
    "                generated_images[0] * 255.0, scale=False\n",
    "            )\n",
    "            img.save(os.path.join(save_dir, \"generated_img\" + str(np.argmax(rand_label1,axis=-1)[0]) + \".png\"))\n",
    "            print(np.argmax(rand_label1,axis=-1)[0])\n",
    "        # To limit execution time we stop after 10 steps.\n",
    "        # Remove the lines below to actually train the model!\n",
    "        # if step > 10:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    random_label1=keras.utils.to_categorical(np.random.randint(10,size=(batch_size,1)))\n",
    "    print(np.argmax(random_label1,axis=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.expand_dims(real_images[0,...],axis=0)\n",
    "b=tf.reshape(label[4,...],[1,1,1,10])\n",
    "b=tf.tile(b,[1,28,28,1])\n",
    "c=tf.concat([a,b],axis=-1)\n",
    "discriminator(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[0])\n",
    "print(label[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./generator_conditional\") :\n",
    "    os.mkdir(\"./generator_conditional\")\n",
    "generator.save(\"./generator_conditional\")\n",
    "if not os.path.exists(\"./discriminator_conditional\") :\n",
    "    os.mkdir(\"./discriminator_conditional\")\n",
    "discriminator.save(\"./discriminator_conditional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=np.random.random([1,32])\n",
    "data2=np.eye(10)[[0]]\n",
    "data=np.concatenate([data1,data2],axis=-1)\n",
    "plt.imshow(generator(data)[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a=tf.random.normal([2,3,4])\n",
    "b=keras.regularizers.l2(0.1)(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=keras.models.load_model(\"./generator\")\n",
    "dis=keras.models.load_model(\"./discriminator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<tensorflow.python.keras.saving.saved_model.load.Dense object at 0x000001BFF7A8BC08>, <tensorflow.python.keras.saving.saved_model.load.LeakyReLU object at 0x000001BFF7A8C8C8>, <tensorflow.python.keras.saving.saved_model.load.Reshape object at 0x000001BFF7A8CEC8>, <tensorflow.python.keras.saving.saved_model.load.Conv2DTranspose object at 0x000001BFF7A8DBC8>, <tensorflow.python.keras.saving.saved_model.load.LeakyReLU object at 0x000001BFF7A8E388>, <tensorflow.python.keras.saving.saved_model.load.Conv2DTranspose object at 0x000001BFF7A8F048>, <tensorflow.python.keras.saving.saved_model.load.LeakyReLU object at 0x000001BFF7A8F808>, <tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x000001BFF7A90508>]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_value=tf.random.normal([1,128])\n",
    "with tf.GradientTape() as tape:\n",
    "    image=gen(rand_value)\n",
    "    out=dis(image)\n",
    "grade_1=tape.gradient(out,image)\n",
    "grade_l2=tf.square(keras.regularizers.l2(1.0)(grade_1)-1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}